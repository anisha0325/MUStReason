# <span style="color:#006c66;"><b>MUStReason</b></span>: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection
*[*Anisha Saha*](https://anisha0325.github.io/), [*Varsha Suresh*](https://sites.google.com/view/varsha-suresh/), [*Timothy Hospedales*](https://homepages.inf.ed.ac.uk/thospeda/), [*Vera Demberg*](https://www.uni-saarland.de/lehrstuhl/demberg/members/verademberg.html)*  
 

ðŸš§ **Code and dataset are coming soon!** Stay tuned.  
ðŸ”— Project Page: [MUStReason-Project](https://anisha0325.github.io/MUStReason-Project/)  
ðŸ“„ Paper: [arXiv 2503.22399](https://arxiv.org/abs/2510.23727)

---

## ðŸ“Œ Overview

<div style="text-align: justify"

<span style="color:#006c66;"><b>MUStReason</b></span> provides reasoning-aligned annotations that enable detailed evaluation of modality perception and inference failure which are key factors for assessing and improving pragmatic reasoning in multimodal models. In addition, the paper introduces <span style="color:#006c66;"><b>PragCoT</b></span>, a pragmatic reasoning framework for developing complex reasoning abilities in Video-LMs, through the integration of information from multiple modalities and the systematic resolution of sub-problems.

---

## ðŸ§  Abstract

<div style="text-align: justify"

Sarcasm is a specific type of irony which involves discerning what is said from what is meant. Detecting sarcasm depends not only on the literal content of an utterance but also on non-verbal cues such as speakerâ€™s tonality, facial expressions and conversational context. However, current multimodal models struggle with complex tasks like sarcasm detection, which require identifying relevant cues across modalities and pragmatically reasoning over them to infer the speakerâ€™s intention. To explore these limitations in VideoLMs, we introduce MUStReason, a diagnostic benchmark enriched with annotations of modality-specific relevant cues and underlying reasoning steps to identify sarcastic intent. In addition to benchmarking sarcasm classification performance in VideoLMs, using MUStReason we quantitatively and qualitatively evaluate the generated reasoning by disentangling the problem into perception and reasoning and aim to pinpoint the current gaps in these VideoLMs. Furthermore, to facilitate structured pragmatic reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on implied intentions over literal meaning, a property core to detecting sarcasm.


## ðŸ“¬ Contact

For questions, feel free to contact:

**Anisha Saha**  
ðŸ“§ [ansaha@mpi-inf.mpg.de](mailto:ansaha@mpi-inf.mpg.de)  
ðŸ”— [anisha0325.github.io](https://anisha0325.github.io/)

---

## ðŸ“š Citation

If you use this work in your research, please cite:

```bibtex
@misc{saha2025mustreasonbenchmarkdiagnosingpragmatic,
      title={MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection}, 
      author={Anisha Saha and Varsha Suresh and Timothy Hospedales and Vera Demberg},
      year={2025},
      eprint={2510.23727},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2510.23727}, 
}
```
---

_This repository will be updated shortly. Thank you for your interest!_
